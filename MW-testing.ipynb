{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8208545,"sourceType":"datasetVersion","datasetId":4864172}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport time\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nfrom keras import models, layers, optimizers, regularizers\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom skimage.color import rgb2gray\nimport sklearn\nfrom sklearn import model_selection, preprocessing, metrics\nfrom scipy import stats","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T03:57:21.120482Z","iopub.execute_input":"2024-04-26T03:57:21.120936Z","iopub.status.idle":"2024-04-26T03:57:21.127728Z","shell.execute_reply.started":"2024-04-26T03:57:21.120902Z","shell.execute_reply":"2024-04-26T03:57:21.126607Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"# Load and explore dataset","metadata":{}},{"cell_type":"code","source":"wd = '/kaggle/input/woz-speech/'\n#Set training and test folder paths\ntraining_path = wd+'features_train/features_train'\ntest_path = wd+'features_test/features_test'\n\n#Load labels file\nlabels = pd.read_csv(wd+'labels.csv')\n\n#Load feature description files, take out column 0 to use as header for training/test sets\nfeatures = pd.read_csv(wd+'feature_description.csv', encoding_errors='ignore', header=None, index_col=0)\nfeatures = features.index.tolist()\nfeatures","metadata":{"execution":{"iopub.status.busy":"2024-04-26T01:53:21.005834Z","iopub.execute_input":"2024-04-26T01:53:21.006223Z","iopub.status.idle":"2024-04-26T01:53:21.095816Z","shell.execute_reply.started":"2024-04-26T01:53:21.006194Z","shell.execute_reply":"2024-04-26T01:53:21.094495Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['F0semitoneFrom27.5Hz_sma3nz_amean',\n 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n 'loudness_sma3_amean',\n 'loudness_sma3_stddevNorm',\n 'loudness_sma3_percentile20.0',\n 'loudness_sma3_percentile50.0',\n 'loudness_sma3_percentile80.0',\n 'loudness_sma3_pctlrange0-2',\n 'loudness_sma3_meanRisingSlope',\n 'loudness_sma3_stddevRisingSlope',\n 'loudness_sma3_meanFallingSlope',\n 'loudness_sma3_stddevFallingSlope',\n 'spectralFlux_sma3_amean',\n 'spectralFlux_sma3_stddevNorm',\n 'mfcc1_sma3_amean',\n 'mfcc1_sma3_stddevNorm',\n 'mfcc2_sma3_amean',\n 'mfcc2_sma3_stddevNorm',\n 'mfcc3_sma3_amean',\n 'mfcc3_sma3_stddevNorm',\n 'mfcc4_sma3_amean',\n 'mfcc4_sma3_stddevNorm',\n 'jitterLocal_sma3nz_amean',\n 'jitterLocal_sma3nz_stddevNorm',\n 'shimmerLocaldB_sma3nz_amean',\n 'shimmerLocaldB_sma3nz_stddevNorm',\n 'HNRdBACF_sma3nz_amean',\n 'HNRdBACF_sma3nz_stddevNorm',\n 'logRelF0-H1-H2_sma3nz_amean',\n 'logRelF0-H1-H2_sma3nz_stddevNorm',\n 'logRelF0-H1-A3_sma3nz_amean',\n 'logRelF0-H1-A3_sma3nz_stddevNorm',\n 'F1frequency_sma3nz_amean',\n 'F1frequency_sma3nz_stddevNorm',\n 'F1bandwidth_sma3nz_amean',\n 'F1bandwidth_sma3nz_stddevNorm',\n 'F1amplitudeLogRelF0_sma3nz_amean',\n 'F1amplitudeLogRelF0_sma3nz_stddevNorm',\n 'F2frequency_sma3nz_amean',\n 'F2frequency_sma3nz_stddevNorm',\n 'F2bandwidth_sma3nz_amean',\n 'F2bandwidth_sma3nz_stddevNorm',\n 'F2amplitudeLogRelF0_sma3nz_amean',\n 'F2amplitudeLogRelF0_sma3nz_stddevNorm',\n 'F3frequency_sma3nz_amean',\n 'F3frequency_sma3nz_stddevNorm',\n 'F3bandwidth_sma3nz_amean',\n 'F3bandwidth_sma3nz_stddevNorm',\n 'F3amplitudeLogRelF0_sma3nz_amean',\n 'F3amplitudeLogRelF0_sma3nz_stddevNorm',\n 'alphaRatioV_sma3nz_amean',\n 'alphaRatioV_sma3nz_stddevNorm',\n 'hammarbergIndexV_sma3nz_amean',\n 'hammarbergIndexV_sma3nz_stddevNorm',\n 'slopeV0-500_sma3nz_amean',\n 'slopeV0-500_sma3nz_stddevNorm',\n 'slopeV500-1500_sma3nz_amean',\n 'slopeV500-1500_sma3nz_stddevNorm',\n 'spectralFluxV_sma3nz_amean',\n 'spectralFluxV_sma3nz_stddevNorm',\n 'mfcc1V_sma3nz_amean',\n 'mfcc1V_sma3nz_stddevNorm',\n 'mfcc2V_sma3nz_amean',\n 'mfcc2V_sma3nz_stddevNorm',\n 'mfcc3V_sma3nz_amean',\n 'mfcc3V_sma3nz_stddevNorm',\n 'mfcc4V_sma3nz_amean',\n 'mfcc4V_sma3nz_stddevNorm',\n 'alphaRatioUV_sma3nz_amean',\n 'hammarbergIndexUV_sma3nz_amean',\n 'slopeUV0-500_sma3nz_amean',\n 'slopeUV500-1500_sma3nz_amean',\n 'spectralFluxUV_sma3nz_amean',\n 'loudnessPeaksPerSec',\n 'VoicedSegmentsPerSec',\n 'MeanVoicedSegmentLengthSec',\n 'StddevVoicedSegmentLengthSec',\n 'MeanUnvoicedSegmentLength',\n 'StddevUnvoicedSegmentLength',\n 'equivalentSoundLevel_dBp']"},"metadata":{}}]},{"cell_type":"code","source":"def load_data(folder_path):\n    #Init empty dataframe\n    res = pd.DataFrame()\n    for file in os.listdir(folder_path):\n        #for each speaker file\n        if file.endswith('.csv'):\n            #get participant id from filename, eg filename: 'spk_305.csv'\n            participant = float(file.split('_')[1].split('.')[0])\n            #find labels for the participant\n            label = labels[labels['Participant_ID'] == participant]\n            #load participant feature file\n            file_path = os.path.join(folder_path, file)\n            data_df = pd.read_csv(file_path, header=None, names=features)\n            #Add labels and participant id columns\n            data_df['participant'] = participant\n            data_df['gender'] = label['Gender'].values[0]\n            data_df['depression'] = label['Depression'].values[0]\n            #combine everything to result\n            res = pd.concat([res, data_df])\n    return res","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:04:55.350903Z","iopub.execute_input":"2024-04-26T02:04:55.351287Z","iopub.status.idle":"2024-04-26T02:04:55.359754Z","shell.execute_reply.started":"2024-04-26T02:04:55.351258Z","shell.execute_reply":"2024-04-26T02:04:55.358341Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Load training data\ntraining_df = load_data(training_path)\nlen(training_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:04:58.516765Z","iopub.execute_input":"2024-04-26T02:04:58.517086Z","iopub.status.idle":"2024-04-26T02:04:59.918387Z","shell.execute_reply.started":"2024-04-26T02:04:58.517065Z","shell.execute_reply":"2024-04-26T02:04:59.917021Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"13626"},"metadata":{}}]},{"cell_type":"code","source":"#Load test data\ntest_df = load_data(test_path)\nlen(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:05:03.518291Z","iopub.execute_input":"2024-04-26T02:05:03.518661Z","iopub.status.idle":"2024-04-26T02:05:03.835506Z","shell.execute_reply.started":"2024-04-26T02:05:03.518638Z","shell.execute_reply":"2024-04-26T02:05:03.834353Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"3280"},"metadata":{}}]},{"cell_type":"code","source":"# Check Missing values\nmissing_values = (training_df.isnull().sum()/len(training_df)) *100\nprint(f'Missing value percent % for each column, total samples {len(training_df)}')\nprint(missing_values)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:05:06.080775Z","iopub.execute_input":"2024-04-26T02:05:06.081145Z","iopub.status.idle":"2024-04-26T02:05:06.095273Z","shell.execute_reply.started":"2024-04-26T02:05:06.081122Z","shell.execute_reply":"2024-04-26T02:05:06.093991Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Missing value percent % for each column, total samples 13626\nF0semitoneFrom27.5Hz_sma3nz_amean             0.007339\nF0semitoneFrom27.5Hz_sma3nz_stddevNorm        0.007339\nF0semitoneFrom27.5Hz_sma3nz_percentile20.0    0.007339\nF0semitoneFrom27.5Hz_sma3nz_percentile50.0    0.007339\nF0semitoneFrom27.5Hz_sma3nz_percentile80.0    0.007339\n                                                ...   \nStddevUnvoicedSegmentLength                   0.007339\nequivalentSoundLevel_dBp                      0.007339\nparticipant                                   0.000000\ngender                                        0.000000\ndepression                                    0.000000\nLength: 91, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"training_df = training_df.dropna()\nlen(training_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:05:09.557107Z","iopub.execute_input":"2024-04-26T02:05:09.557437Z","iopub.status.idle":"2024-04-26T02:05:09.568808Z","shell.execute_reply.started":"2024-04-26T02:05:09.557415Z","shell.execute_reply":"2024-04-26T02:05:09.567623Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"13625"},"metadata":{}}]},{"cell_type":"markdown","source":"There was only one row with null values so I think we're good to drop that row.","metadata":{}},{"cell_type":"markdown","source":"Designating subjects as validation vs training subjects","metadata":{}},{"cell_type":"code","source":"def val_split(df: pd.DataFrame):\n    df['participant'] = df['participant'].astype(int)\n    n = np.unique(df['participant'])\n    n_range = range(min(n), max(n))\n    train_subs = random.sample(n_range, math.floor(len(n)*0.75))\n    train = df[df['participant'].isin(train_subs)]\n    val = df[~df['participant'].isin(train_subs)]\n    return train, val","metadata":{"execution":{"iopub.status.busy":"2024-04-26T02:49:59.761587Z","iopub.execute_input":"2024-04-26T02:49:59.761968Z","iopub.status.idle":"2024-04-26T02:49:59.768052Z","shell.execute_reply.started":"2024-04-26T02:49:59.761937Z","shell.execute_reply":"2024-04-26T02:49:59.767087Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train, val = val_split(training_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:48:44.176559Z","iopub.execute_input":"2024-04-26T04:48:44.176933Z","iopub.status.idle":"2024-04-26T04:48:44.192757Z","shell.execute_reply.started":"2024-04-26T04:48:44.176910Z","shell.execute_reply":"2024-04-26T04:48:44.191200Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"#Used to split into our features and our outcomes for this task\ndef x_y_split(df: pd.DataFrame):\n    x = df.drop(['participant', 'gender', 'depression'], axis = 1)\n    gender = df['gender']\n    depression = df['depression']\n    return x, gender, depression","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:00:12.165449Z","iopub.execute_input":"2024-04-26T03:00:12.165811Z","iopub.status.idle":"2024-04-26T03:00:12.170726Z","shell.execute_reply.started":"2024-04-26T03:00:12.165789Z","shell.execute_reply":"2024-04-26T03:00:12.169796Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"x_train, g_train, d_train = x_y_split(train)\nx_val, g_val, d_val = x_y_split(val)\nx_test, g_test, d_test = x_y_split(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:48:47.381314Z","iopub.execute_input":"2024-04-26T04:48:47.381702Z","iopub.status.idle":"2024-04-26T04:48:47.390077Z","shell.execute_reply.started":"2024-04-26T04:48:47.381673Z","shell.execute_reply":"2024-04-26T04:48:47.388717Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n# Calculates accuracy\n# pass true and predicted labels\n# return accuracy score\ndef calculate_total_accuracy(true_labels, predicted_labels):\n    return accuracy_score(true_labels, predicted_labels)\n\n# Calculates accuracy\n# pass true and predicted labels\n# return balanced accuracy score\ndef calculate_balanced_accuracy(true_labels, predicted_labels):\n    #calculkate confusion matrix\n    matrix = confusion_matrix(true_labels, predicted_labels)\n    TP = matrix[1, 1]\n    TN = matrix[0, 0]\n    FP = matrix[0, 1]\n    FN = matrix[1, 0]\n    #For positive class, how many correct predictions\n    accuracy_positive = TP/(TP+FN)\n    #For negative class how many \n    accuracy_negative = TN/(TN+FP)\n    return 0.5*(accuracy_positive + accuracy_negative)\n\n#Calculates Equality of Opportunity\n# pass true and predicted labels for male samples\n# pass true and predicted labels for female samples\n# return balanced accuracy score\ndef calculate_EO(true_labels_male, \n                 true_labels_female,\n                 predicted_labels_male,\n                predicted_labels_female):\n    #Calculate True pistive rate for male gender with confusion matrix\n    matrix_male = confusion_matrix(true_labels_male, predicted_labels_male)\n    TP = matrix_male[1, 1]\n    TN = matrix_male[0, 0]\n    FN = matrix_male[1, 0]\n    TPR_male = TP/(TP+FN)\n\n    #Calculate True pistive rate for female gender with confusion matrix\n    matrix_female = confusion_matrix(true_labels_female, predicted_labels_female)\n    TP = matrix_female[1, 1]\n    TN = matrix_female[0, 0]\n    FN = matrix_female[1, 0]\n    TPR_female = TP/(TP+FN)\n    \n    # Calculate EO\n    return 1-abs(TPR_male-TPR_female) \n\n#Function to calculate majority votings\n#Pass labels\n#Returns mode or which label was predicted most\ndef majority_voting(df):\n    counts = df.value_counts()\n    return counts.idxmax()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:57:51.455276Z","iopub.execute_input":"2024-04-26T03:57:51.455662Z","iopub.status.idle":"2024-04-26T03:57:51.465426Z","shell.execute_reply.started":"2024-04-26T03:57:51.455633Z","shell.execute_reply":"2024-04-26T03:57:51.464218Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#Function to calculate all metrics\n#Pass true labels, predicted labels and a reference(test/val) dataframe\n#referece dataframe should have all labels and features\n#Returns a dictionary with all the metric calculated\ndef calculate_metrics(y_true, y_pred, test_data):\n    # Initialize metrics\n    metrics = {}\n    #---------------------------------------------------CALCULATING TOTAL METRICS\n    #calculate total accuracy\n    metrics[\"Total accuracy\"] = calculate_total_accuracy(y_true, y_pred)\n    #calculate total balanced accuracy\n    metrics[\"Total Balanced accuracy\"] = calculate_balanced_accuracy(y_true, y_pred)\n    #calculate total EO\n    #find gender based indices for true labels from data\n    male_indices = test_data[test_data['gender']==1].index\n    female_indices = test_data[test_data['gender']==0].index\n    #separate true labels based on indices\n    male_true = y_true.loc[male_indices]\n    female_true = y_true.loc[female_indices]\n    #Find the corresponding indices for predicted labels from true_labels\n    male_true_index_list = male_true.index.tolist()\n    female_true_index_list = female_true.index.tolist()\n    #Get separated predicted labels based on gender\n    male_predicted = y_pred[[male_true_index_list.index(index) for index in male_true_index_list]]\n    female_predicted = y_pred[[female_true_index_list.index(index) for index in female_true_index_list]]\n    metrics[\"Total EO\"] = calculate_EO(male_true, female_true, male_predicted, female_predicted)\n    #-------------------------------------------------CALCULATING AGGREGATED METRICS FOR EACH PARTICIPANT\n    predictions_df = pd.DataFrame({'participant': test_data['participant'], 'predicted_label': y_pred, 'true_label': y_true})\n    aggregated_y_true = predictions_df.groupby('participant')['true_label'].agg(majority_voting)\n    aggregated_y_pred = predictions_df.groupby('participant')['predicted_label'].agg(majority_voting)\n    #Calculate aggregated accuracy score\n    metrics[\"Aggregated accuracy score\"] = calculate_total_accuracy(aggregated_y_true, aggregated_y_pred)\n    #Calculate balanced aggregated accuracy\n    metrics[\"Aggregated balanced accuracy score\"] = calculate_balanced_accuracy(aggregated_y_true, aggregated_y_pred)\n    #Calculate aggregated EOs\n    male_predictions_df = pd.DataFrame({'participant': test_data['participant'].loc[male_indices], 'predicted_label': y_pred, 'true_label': y_true})\n    male_aggregated_y_true = male_predictions_df.groupby('participant')['true_label'].agg(majority_voting)\n    male_aggregated_y_pred = male_predictions_df.groupby('participant')['predicted_label'].agg(majority_voting)\n    female_predictions_df = pd.DataFrame({'participant': test_data['participant'].loc[female_indices], 'predicted_label': y_pred, 'true_label': y_true})\n    female_aggregated_y_true = female_predictions_df.groupby('participant')['true_label'].agg(majority_voting)\n    female_aggregated_y_pred = female_predictions_df.groupby('participant')['predicted_label'].agg(majority_voting)\n    metrics[\"Aggregated EO score\"] = calculate_EO(male_aggregated_y_true, female_aggregated_y_true, male_aggregated_y_pred, female_aggregated_y_pred)\n    \n    return metrics","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:57:56.830496Z","iopub.execute_input":"2024-04-26T03:57:56.830843Z","iopub.status.idle":"2024-04-26T03:57:56.842161Z","shell.execute_reply.started":"2024-04-26T03:57:56.830821Z","shell.execute_reply":"2024-04-26T03:57:56.841001Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"# Feature selection","metadata":{}},{"cell_type":"markdown","source":"Running PCA to find the principal components in the data.","metadata":{}},{"cell_type":"code","source":"from sklearn import decomposition\nfrom sklearn.feature_selection import SelectKBest","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:22:27.973321Z","iopub.execute_input":"2024-04-26T03:22:27.973694Z","iopub.status.idle":"2024-04-26T03:22:27.978521Z","shell.execute_reply.started":"2024-04-26T03:22:27.973671Z","shell.execute_reply":"2024-04-26T03:22:27.977361Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"class PCA_(decomposition.PCA):\n    def __init__(self, x_train, x_val, x_test):\n        super().__init__()\n        self.x_train = x_train\n        self.x_val = x_val\n        self.x_test = x_test\n    \n    def run_pca(self):\n        #Find all PCs for the data\n        self.fit(self.x_train)\n        #Transform the data into the new feature space\n        self.x_train = self.transform(self.x_train)\n        self.x_val = self.transform(self.x_val)\n        self.x_test = self.transform(self.x_test)\n    \n    def best_PCs(self, Y, k):\n        #Find the k best PCs for predicting a given outcome Y\n        best = SelectKBest(k=k).fit(self.x_train, Y)\n        return best.transform(self.x_train), best.transform(self.x_val), best.transform(self.x_test)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:50:07.089825Z","iopub.execute_input":"2024-04-26T04:50:07.090169Z","iopub.status.idle":"2024-04-26T04:50:07.098952Z","shell.execute_reply.started":"2024-04-26T04:50:07.090146Z","shell.execute_reply":"2024-04-26T04:50:07.097631Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"pca = PCA_(x_train, x_val, x_test)\npca.run_pca()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:50:09.490529Z","iopub.execute_input":"2024-04-26T04:50:09.490922Z","iopub.status.idle":"2024-04-26T04:50:09.559529Z","shell.execute_reply.started":"2024-04-26T04:50:09.490897Z","shell.execute_reply":"2024-04-26T04:50:09.558772Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"Running independent component analysis to compare to PCA.","metadata":{}},{"cell_type":"code","source":"class ICA_(decomposition.FastICA):\n    def __init__(self, x_train, x_val, x_test):\n        super().__init__()\n        self.x_train = x_train\n        self.x_val = x_val\n        self.x_test = x_test\n    \n    def run_ica(self):\n        #Find all ICs for the data\n        self.fit(self.x_train)\n        #Transform the data into the new feature space\n        self.x_train = self.transform(self.x_train)\n        self.x_val = self.transform(self.x_val)\n        self.x_test = self.transform(self.x_test)\n    \n    def best_ICs(self, Y, k):\n        #Find the k best ICs for predicting a given outcome Y\n        best = SelectKBest(k=k).fit(self.x_train, Y)\n        return best.transform(self.x_train), best.transform(self.x_val), best.transform(self.x_test)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:50:19.049654Z","iopub.execute_input":"2024-04-26T04:50:19.050039Z","iopub.status.idle":"2024-04-26T04:50:19.058356Z","shell.execute_reply.started":"2024-04-26T04:50:19.050009Z","shell.execute_reply":"2024-04-26T04:50:19.056674Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"ica = ICA_(x_train, x_val, x_test)\nica.run_ica()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:50:27.868501Z","iopub.execute_input":"2024-04-26T04:50:27.868877Z","iopub.status.idle":"2024-04-26T04:50:30.156523Z","shell.execute_reply.started":"2024-04-26T04:50:27.868853Z","shell.execute_reply":"2024-04-26T04:50:30.155751Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_fastica.py:542: FutureWarning: Starting in v1.3, whiten='unit-variance' will be used by default.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Linear Perceptron\nCreate a linear perceptron from the PCs that best predict gender and depression.","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:27:46.436749Z","iopub.execute_input":"2024-04-26T03:27:46.437123Z","iopub.status.idle":"2024-04-26T03:27:46.442222Z","shell.execute_reply.started":"2024-04-26T03:27:46.437094Z","shell.execute_reply":"2024-04-26T03:27:46.441026Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def perceptron(x_train, y_train, x_val, y_val):\n    percept = linear_model.Perceptron()\n    percept.fit(x_train, y_train)\n    preds = percept.predict(x_val)\n    return calculate_balanced_accuracy(y_val, preds)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:12:21.399653Z","iopub.execute_input":"2024-04-26T04:12:21.399999Z","iopub.status.idle":"2024-04-26T04:12:21.404883Z","shell.execute_reply.started":"2024-04-26T04:12:21.399975Z","shell.execute_reply":"2024-04-26T04:12:21.404098Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"pc_g_stats = {}\nic_g_stats = {}\nfor k in range(1, 60):\n    g_x_train, g_x_val, g_x_test = pca.best_PCs(g_train, k)\n    pc_g_stats[k] = perceptron(g_x_train, g_train, g_x_val, g_val)\n    \n    g_x_train, g_x_val, g_x_test = ica.best_ICs(g_train, k)\n    ic_g_stats[k] = perceptron(g_x_train, g_train, g_x_val, g_val)\n\ng_n_pcs_best = max(pc_g_stats, key=pc_g_stats.get)\ng_acc_best = pc_g_stats[g_n_pcs_best]\n\nprint('For predicting gender with PCs, the best performance was achieved by using the', g_n_pcs_best, 'best PCs. This achieved a balanced accuracy of', g_acc_best)\n\ng_n_ics_best = max(ic_g_stats, key=ic_g_stats.get)\ng_acc_best = ic_g_stats[g_n_ics_best]\n\nprint('For predicting gender with ICs, the best performance was achieved by using the', g_n_ics_best, 'best ICs. This achieved a balanced accuracy of', g_acc_best)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:50:37.232294Z","iopub.execute_input":"2024-04-26T04:50:37.233108Z","iopub.status.idle":"2024-04-26T04:50:39.366488Z","shell.execute_reply.started":"2024-04-26T04:50:37.233081Z","shell.execute_reply":"2024-04-26T04:50:39.365823Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"For predicting gender with PCs, the best performance was achieved by using the 19 best PCs. This achieved a balanced accuracy of 0.8927601570004363\nFor predicting gender with ICs, the best performance was achieved by using the 43 best ICs. This achieved a balanced accuracy of 0.9115269387501703\n","output_type":"stream"}]},{"cell_type":"code","source":"pc_d_stats = {}\nic_d_stats = {}\nfor k in range(1, 60):\n    d_x_train, d_x_val, d_x_test = pca.best_PCs(d_train, k)\n    pc_d_stats[k] = perceptron(d_x_train, d_train, d_x_val, d_val)\n    \n    d_x_train, d_x_val, d_x_test = ica.best_ICs(d_train, k)\n    ic_d_stats[k] = perceptron(d_x_train, d_train, d_x_val, d_val)\n\nd_n_pcs_best = max(pc_d_stats, key=pc_d_stats.get)\nd_acc_best = pc_d_stats[d_n_pcs_best]\n\nprint('For predicting depression with PCs, the best performance was achieved by using the', d_n_pcs_best, 'best PCs. This achieved a balanced accuracy of', d_acc_best)\n\nd_n_ics_best = max(ic_d_stats, key=ic_d_stats.get)\nd_acc_best = ic_d_stats[d_n_ics_best]\n\nprint('For predicting depression with ICs, the best performance was achieved by using the', d_n_ics_best, 'best ICs. This achieved a balanced accuracy of', d_acc_best)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:50:55.124088Z","iopub.execute_input":"2024-04-26T04:50:55.124465Z","iopub.status.idle":"2024-04-26T04:50:56.989040Z","shell.execute_reply.started":"2024-04-26T04:50:55.124435Z","shell.execute_reply":"2024-04-26T04:50:56.988196Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"For predicting depression with PCs, the best performance was achieved by using the 17 best PCs. This achieved a balanced accuracy of 0.5414190093509015\nFor predicting depression with ICs, the best performance was achieved by using the 57 best ICs. This achieved a balanced accuracy of 0.5316878136781915\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}