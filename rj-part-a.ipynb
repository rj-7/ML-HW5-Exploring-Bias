{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6361ec3-2edd-4c41-8ed8-2a72d9df920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb69e9-0484-4573-9a52-244bacec9342",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf06caca-f53c-4b96-a9a8-bd9b9898dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training and test folder paths\n",
    "training_path = 'features_train/features_train'\n",
    "test_path = 'features_test/features_test'\n",
    "\n",
    "#Load labels file\n",
    "labels = pd.read_csv('labels.csv')\n",
    "\n",
    "#Load feature description files, take out column 0 to use as header for training/test sets\n",
    "features = pd.read_csv('feature_description.csv', encoding_errors='ignore', header=None, index_col=0)\n",
    "features = features.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb8a6c5-8959-4820-a408-437f9089aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    #Init empty dataframe\n",
    "    res = pd.DataFrame()\n",
    "    for file in os.listdir(folder_path):\n",
    "        #for each speaker file\n",
    "        if file.endswith('.csv'):\n",
    "            #get participant id from filename, eg filename: 'spk_305.csv'\n",
    "            participant = float(file.split('_')[1].split('.')[0])\n",
    "            #find labels for the participant\n",
    "            label = labels[labels['Participant_ID'] == participant]\n",
    "            #load participant feature file\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data_df = pd.read_csv(file_path, header=None, names=features)\n",
    "            #Add labels and participant id columns\n",
    "            data_df['participant'] = participant\n",
    "            data_df['gender'] = label['Gender'].values[0]\n",
    "            data_df['depression'] = label['Depression'].values[0]\n",
    "            #combine everything to result\n",
    "            res = pd.concat([res, data_df])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9f8ea7-287e-44b8-8b78-b25daaeadff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13626"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load training data\n",
    "training_df = load_data(training_path)\n",
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6652d62d-a35b-43a5-84c5-7c39d7fa8562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load test data\n",
    "test_df = load_data(test_path)\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60ae20c-5d3d-48d7-a64c-545a50a9c753",
   "metadata": {},
   "source": [
    "## Data cleaning and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2c085a-988f-416a-9abd-e2037a69d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value percent % for each column, total samples 13626\n",
      "Number of samples with missing values: 1\n",
      "F0semitoneFrom27.5Hz_sma3nz_amean             0.007339\n",
      "F0semitoneFrom27.5Hz_sma3nz_stddevNorm        0.007339\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile20.0    0.007339\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile50.0    0.007339\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile80.0    0.007339\n",
      "                                                ...   \n",
      "StddevUnvoicedSegmentLength                   0.007339\n",
      "equivalentSoundLevel_dBp                      0.007339\n",
      "participant                                   0.000000\n",
      "gender                                        0.000000\n",
      "depression                                    0.000000\n",
      "Length: 91, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check Missing values\n",
    "missing_values = (training_df.isnull().sum()/len(training_df)) *100\n",
    "total_missing_values = training_df.isnull().any(axis=1).sum()\n",
    "print(f'Missing value percent % for each column, total samples {len(training_df)}')\n",
    "print(f'Number of samples with missing values: {total_missing_values}')\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccaa72fa-f720-4c61-ad92-a771e07c9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    #drop missing va;ues since there is just 1 sample\n",
    "    data_nona = data.dropna()\n",
    "    #Normalization z-score\n",
    "    scaler = StandardScaler()    \n",
    "    # Store the columns to keep for later concatenation\n",
    "    columns_to_keep = ['participant', 'gender', 'depression']\n",
    "    # Extract the columns to be scaled and drop them from the original DataFrame\n",
    "    temp = data_nona[columns_to_keep].copy()\n",
    "    data_nona.drop(columns=columns_to_keep, axis=1, inplace=True)\n",
    "    # Scale the remaining columns using StandardScaler and convert back to DataFrame\n",
    "    scaled_data = pd.DataFrame(scaler.fit_transform(data_nona), columns=data_nona.columns)\n",
    "    scaled_data.reset_index(drop=True, inplace=True)\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "    # Concatenate the scaled data with the columns we kept earlier\n",
    "    processed_data = pd.concat([scaled_data, temp], axis=1)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afcae2-ac22-4117-a04e-9434806d7569",
   "metadata": {},
   "source": [
    "## Methods to calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1453e6-d155-47fc-b17a-03d19987f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates accuracy\n",
    "# pass true and predicted labels\n",
    "# return accuracy score\n",
    "def calculate_total_accuracy(true_labels, predicted_labels):\n",
    "    return accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculates accuracy\n",
    "# pass true and predicted labels\n",
    "# return balanced accuracy score\n",
    "def calculate_balanced_accuracy(true_labels, predicted_labels):\n",
    "    #calculkate confusion matrix\n",
    "    matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "    TP = matrix[1, 1]\n",
    "    TN = matrix[0, 0]\n",
    "    FP = matrix[0, 1]\n",
    "    FN = matrix[1, 0]\n",
    "    #For positive class, how many correct predictions\n",
    "    accuracy_positive = TP/(TP+FN)\n",
    "    #For negative class how many \n",
    "    accuracy_negative = TN/(TN+FP)\n",
    "    return 0.5*(accuracy_positive + accuracy_negative)\n",
    "\n",
    "#Calculates Equality of Opportunity\n",
    "# pass true and predicted labels for male samples\n",
    "# pass true and predicted labels for female samples\n",
    "# return balanced accuracy score\n",
    "def calculate_EO(true_labels_male, \n",
    "                 true_labels_female,\n",
    "                 predicted_labels_male,\n",
    "                predicted_labels_female):\n",
    "    #Calculate True pistive rate for male gender with confusion matrix\n",
    "    matrix_male = confusion_matrix(true_labels_male, predicted_labels_male)\n",
    "    TP = matrix_male[1, 1]\n",
    "    TN = matrix_male[0, 0]\n",
    "    FN = matrix_male[1, 0]\n",
    "    TPR_male = TP/(TP+FN)\n",
    "\n",
    "    #Calculate True pistive rate for female gender with confusion matrix\n",
    "    matrix_female = confusion_matrix(true_labels_female, predicted_labels_female)\n",
    "    TP = matrix_female[1, 1]\n",
    "    TN = matrix_female[0, 0]\n",
    "    FN = matrix_female[1, 0]\n",
    "    TPR_female = TP/(TP+FN)\n",
    "    \n",
    "    # Calculate EO\n",
    "    return 1-abs(TPR_male-TPR_female) \n",
    "\n",
    "#Function to calculate majority votings\n",
    "#Pass labels\n",
    "#Returns mode or which label was predicted most\n",
    "def majority_voting(df):\n",
    "    counts = df.value_counts()\n",
    "    return counts.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63781b8a-f603-4075-b8ba-a252f66bac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate all metrics\n",
    "#Pass true labels, predicted labels and a reference(test/val) dataframe\n",
    "#referece dataframe should have all labels and features\n",
    "#Returns a dictionary with all the metric calculated\n",
    "def calculate_metrics(y_true, y_pred, test_data, EO=True):\n",
    "    # Initialize metrics\n",
    "    metrics = {}\n",
    "    #---------------------------------------------------CALCULATING TOTAL METRICS\n",
    "    #calculate total accuracy\n",
    "    metrics[\"Total accuracy\"] = calculate_total_accuracy(y_true, y_pred)\n",
    "    #calculate total balanced accuracy\n",
    "    metrics[\"Total Balanced accuracy\"] = calculate_balanced_accuracy(y_true, y_pred)\n",
    "    #calculate total EO\n",
    "    if(EO):\n",
    "        #find gender based indices for true labels from data\n",
    "        male_indices = test_data[test_data['gender']==1].index\n",
    "        female_indices = test_data[test_data['gender']==0].index\n",
    "        #separate true labels based on indices\n",
    "        male_true = y_true.loc[male_indices]\n",
    "        female_true = y_true.loc[female_indices]\n",
    "        #Find the corresponding indices for predicted labels from true_labels\n",
    "        male_true_index_list = male_true.index.tolist()\n",
    "        female_true_index_list = female_true.index.tolist()\n",
    "        #Get separated predicted labels based on gender\n",
    "        male_predicted = y_pred[[male_true_index_list.index(index) for index in male_true_index_list]]\n",
    "        female_predicted = y_pred[[female_true_index_list.index(index) for index in female_true_index_list]]\n",
    "        metrics[\"Total EO\"] = calculate_EO(male_true, female_true, male_predicted, female_predicted)\n",
    "    #-------------------------------------------------CALCULATING AGGREGATED METRICS FOR EACH PARTICIPANT\n",
    "    predictions_df = pd.DataFrame({'participant': test_data['participant'], 'predicted_label': y_pred, 'true_label': y_true})\n",
    "    aggregated_y_true = predictions_df.groupby('participant')['true_label'].agg(majority_voting)\n",
    "    aggregated_y_pred = predictions_df.groupby('participant')['predicted_label'].agg(majority_voting)\n",
    "    #Calculate aggregated accuracy score\n",
    "    metrics[\"Aggregated accuracy score\"] = calculate_total_accuracy(aggregated_y_true, aggregated_y_pred)\n",
    "    #Calculate balanced aggregated accuracy\n",
    "    metrics[\"Aggregated balanced accuracy score\"] = calculate_balanced_accuracy(aggregated_y_true, aggregated_y_pred)\n",
    "    if(EO):\n",
    "        #Calculate aggregated EOs\n",
    "        male_predictions_df = pd.DataFrame({'participant': test_data['participant'].loc[male_indices], 'predicted_label': y_pred, 'true_label': y_true})\n",
    "        male_aggregated_y_true = male_predictions_df.groupby('participant')['true_label'].agg(majority_voting)\n",
    "        male_aggregated_y_pred = male_predictions_df.groupby('participant')['predicted_label'].agg(majority_voting)\n",
    "        female_predictions_df = pd.DataFrame({'participant': test_data['participant'].loc[female_indices], 'predicted_label': y_pred, 'true_label': y_true})\n",
    "        female_aggregated_y_true = female_predictions_df.groupby('participant')['true_label'].agg(majority_voting)\n",
    "        female_aggregated_y_pred = female_predictions_df.groupby('participant')['predicted_label'].agg(majority_voting)\n",
    "        metrics[\"Aggregated EO score\"] = calculate_EO(male_aggregated_y_true, female_aggregated_y_true, male_aggregated_y_pred, female_aggregated_y_pred)\n",
    "        metrics[\"Aggregated balanced accuracy score (male)\"] = calculate_balanced_accuracy(male_aggregated_y_true, male_aggregated_y_pred)\n",
    "        metrics[\"Aggregated balanced accuracy score (female)\"] = calculate_balanced_accuracy(female_aggregated_y_true, female_aggregated_y_pred)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2503eab-929d-4284-ac8b-b6e01732ebed",
   "metadata": {},
   "source": [
    "## Data Modeling - Depression Classification\n",
    "### What models to try?\n",
    "- Decision tree\n",
    "- Random forest\n",
    "- Logistic Regression\n",
    "- Adaboost Classifier\n",
    "- Linear Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f0769-2394-44e0-a91e-535db7b7e2e8",
   "metadata": {},
   "source": [
    "### Model attempt: Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2c4d21-e943-4705-a523-ff1c9d7796cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth 3\n",
      "{'Total accuracy': 0.739302752293578, 'Total Balanced accuracy': 0.5909240479132576, 'Total EO': 0.9504593123805108, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5857142857142856, 'Aggregated EO score': 0.8333333333333334, 'Aggregated balanced accuracy score (male)': 0.5750000000000001, 'Aggregated balanced accuracy score (female)': 0.5875}\n",
      "\n",
      "for depth 5\n",
      "{'Total accuracy': 0.7470825688073395, 'Total Balanced accuracy': 0.613583936397171, 'Total EO': 0.9324445056229891, 'Aggregated accuracy score': 0.7839080459770115, 'Aggregated balanced accuracy score': 0.6109126984126985, 'Aggregated EO score': 0.8833333333333332, 'Aggregated balanced accuracy score (male)': 0.6083333333333334, 'Aggregated balanced accuracy score (female)': 0.6125}\n",
      "\n",
      "for depth 7\n",
      "{'Total accuracy': 0.7634495412844037, 'Total Balanced accuracy': 0.6655559677154813, 'Total EO': 0.9631518642013741, 'Aggregated accuracy score': 0.8137931034482758, 'Aggregated balanced accuracy score': 0.6728174603174604, 'Aggregated EO score': 0.8166666666666667, 'Aggregated balanced accuracy score (male)': 0.6333333333333333, 'Aggregated balanced accuracy score (female)': 0.7083333333333333}\n",
      "\n",
      "for depth 9\n",
      "{'Total accuracy': 0.7694678899082569, 'Total Balanced accuracy': 0.6873215037762088, 'Total EO': 0.9772856010148189, 'Aggregated accuracy score': 0.8413793103448276, 'Aggregated balanced accuracy score': 0.7253968253968254, 'Aggregated EO score': 0.8333333333333333, 'Aggregated balanced accuracy score (male)': 0.7166666666666668, 'Aggregated balanced accuracy score (female)': 0.7291666666666667}\n",
      "\n",
      "for depth 15\n",
      "{'Total accuracy': 0.7631559633027523, 'Total Balanced accuracy': 0.7081565396161938, 'Total EO': 0.9823706822360929, 'Aggregated accuracy score': 0.9057471264367816, 'Aggregated balanced accuracy score': 0.8394841269841271, 'Aggregated EO score': 0.8833333333333334, 'Aggregated balanced accuracy score (male)': 0.8583333333333332, 'Aggregated balanced accuracy score (female)': 0.8166666666666667}\n",
      "\n",
      "for depth 30\n",
      "{'Total accuracy': 0.7544220183486239, 'Total Balanced accuracy': 0.704552949439287, 'Total EO': 0.9822539552979415, 'Aggregated accuracy score': 0.9126436781609195, 'Aggregated balanced accuracy score': 0.8519841269841268, 'Aggregated EO score': 0.8333333333333334, 'Aggregated balanced accuracy score (male)': 0.8416666666666666, 'Aggregated balanced accuracy score (female)': 0.8583333333333334}\n",
      "\n",
      "for depth 50\n",
      "{'Total accuracy': 0.753834862385321, 'Total Balanced accuracy': 0.7034405172426037, 'Total EO': 0.9820855702353741, 'Aggregated accuracy score': 0.9149425287356323, 'Aggregated balanced accuracy score': 0.8535714285714284, 'Aggregated EO score': 0.8666666666666668, 'Aggregated balanced accuracy score (male)': 0.8666666666666666, 'Aggregated balanced accuracy score (female)': 0.8375000000000001}\n",
      "\n",
      "for depth 70\n",
      "{'Total accuracy': 0.7528073394495414, 'Total Balanced accuracy': 0.7037180052662739, 'Total EO': 0.9691163900390188, 'Aggregated accuracy score': 0.9149425287356323, 'Aggregated balanced accuracy score': 0.8509920634920636, 'Aggregated EO score': 0.9166666666666667, 'Aggregated balanced accuracy score (male)': 0.8583333333333334, 'Aggregated balanced accuracy score (female)': 0.8416666666666668}\n",
      "\n",
      "for depth 90\n",
      "{'Total accuracy': 0.7530275229357799, 'Total Balanced accuracy': 0.702054922437396, 'Total EO': 0.9782107586658959, 'Aggregated accuracy score': 0.9172413793103449, 'Aggregated balanced accuracy score': 0.8577380952380953, 'Aggregated EO score': 0.9166666666666667, 'Aggregated balanced accuracy score (male)': 0.8583333333333332, 'Aggregated balanced accuracy score (female)': 0.8541666666666667}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------Tuning for different depths-------------------------------------------------------\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['depression']\n",
    "\n",
    "# Define the depths to experiment with\n",
    "depths = [3, 5, 7, 9, 15, 30, 50, 70, 90]\n",
    "# Initialize metrics\n",
    "metrics = {}\n",
    "\n",
    "# Perform cross-validation for each tree depth\n",
    "for depth in depths:\n",
    "    # Initialize decision tree model\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, criterion='entropy')\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        #Fit the training set\n",
    "        tree.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = tree.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index]))\n",
    "\n",
    "    #find avg metrics for each depth\n",
    "    metrics[depth] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    metrics[depth] = sums\n",
    "\n",
    "#Print metrics for all the hyperparameters (Depth)\n",
    "for depth in metrics:\n",
    "    print(f\"for depth {depth}\")\n",
    "    print(metrics[depth])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f350c55a-6fa3-45e4-8c4e-8023129d953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.688109756097561, 'Total Balanced accuracy': 0.5868557627337944, 'Total EO': 0.7612878309107507, 'Aggregated accuracy score': 0.7, 'Aggregated balanced accuracy score': 0.5476190476190477, 'Aggregated EO score': 0.8, 'Aggregated balanced accuracy score (male)': 0.45454545454545453, 'Aggregated balanced accuracy score (female)': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best depth----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['depression']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['depression']\n",
    "\n",
    "best_depth = 70\n",
    "# Initialize decision tree model\n",
    "tree = DecisionTreeClassifier(max_depth=best_depth, criterion='entropy')\n",
    "#Fit the training set\n",
    "tree.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = tree.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd8a4b-eb5a-4222-8cf0-9ec59f3177e6",
   "metadata": {},
   "source": [
    "## Model attempt: Logistic regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224d0b90-adc4-4685-a3c0-673dc06127ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.7428256880733944, 'Total Balanced accuracy': 0.5884060803856384, 'Total EO': 0.9477892614269802, 'Aggregated accuracy score': 0.7609195402298852, 'Aggregated balanced accuracy score': 0.5666666666666667, 'Aggregated EO score': 0.9333333333333332, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5666666666666667}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.7423119266055046, 'Total Balanced accuracy': 0.5882667934329493, 'Total EO': 0.9466991528254788, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5625, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5583333333333333}\n",
      "{'penalty': 'l2', 'C': 0.99, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.7422385321100918, 'Total Balanced accuracy': 0.5882157209099668, 'Total EO': 0.9466991528254788, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5625, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5583333333333333}\n",
      "{'penalty': 'l2', 'C': 0.95, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.7422385321100918, 'Total Balanced accuracy': 0.5882157209099668, 'Total EO': 0.9466991528254788, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5625, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5583333333333333}\n",
      "{'penalty': 'l2', 'C': 0.9, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.7423119266055046, 'Total Balanced accuracy': 0.5881951199255223, 'Total EO': 0.9466991528254788, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5625, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5583333333333333}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'lbfgs'}\n",
      "{'Total accuracy': 0.7422385321100917, 'Total Balanced accuracy': 0.5879845089943649, 'Total EO': 0.9467826783811434, 'Aggregated accuracy score': 0.7563218390804598, 'Aggregated balanced accuracy score': 0.5583333333333333, 'Aggregated EO score': 0.9333333333333332, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5499999999999999}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'sag'}\n",
      "{'Total accuracy': 0.7383486238532109, 'Total Balanced accuracy': 0.5795665708266226, 'Total EO': 0.9388864946436513, 'Aggregated accuracy score': 0.7563218390804598, 'Aggregated balanced accuracy score': 0.5583333333333333, 'Aggregated EO score': 0.9333333333333332, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5499999999999999}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'saga'}\n",
      "{'Total accuracy': 0.7377614678899083, 'Total Balanced accuracy': 0.5756836852328879, 'Total EO': 0.9393244676712401, 'Aggregated accuracy score': 0.7517241379310344, 'Aggregated balanced accuracy score': 0.5499999999999999, 'Aggregated EO score': 0.9333333333333332, 'Aggregated balanced accuracy score (male)': 0.55, 'Aggregated balanced accuracy score (female)': 0.5499999999999999}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cg'}\n",
      "{'Total accuracy': 0.7423119266055046, 'Total Balanced accuracy': 0.588190534202405, 'Total EO': 0.9466991528254788, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5625, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5583333333333333}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cholesky'}\n",
      "{'Total accuracy': 0.7423853211009174, 'Total Balanced accuracy': 0.5883189039071547, 'Total EO': 0.9466991528254788, 'Aggregated accuracy score': 0.7586206896551724, 'Aggregated balanced accuracy score': 0.5625, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5666666666666667, 'Aggregated balanced accuracy score (female)': 0.5583333333333333}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['depression']\n",
    "\n",
    "hyperparams = [\n",
    "    {'penalty': 'l1', 'C': 1.0, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 0.99, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 0.95, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 0.9, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'lbfgs'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'sag'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'saga'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cg'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cholesky'},\n",
    "]\n",
    "\n",
    "for hyperparam in hyperparams:\n",
    "    print(hyperparam)\n",
    "    # Initialize Logistic regression model\n",
    "    model = LogisticRegression(solver=hyperparam['solver'], C=hyperparam['C'], penalty=hyperparam['penalty'])\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index]))\n",
    "    \n",
    "    #find avg metrics for each depth\n",
    "    # metrics[depth] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d2085a-fc61-4f72-9b1d-61d51bb9c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.761890243902439, 'Total Balanced accuracy': 0.5125821245273796, 'Total EO': 0.9488448844884488, 'Aggregated accuracy score': 0.7, 'Aggregated balanced accuracy score': 0.5, 'Aggregated EO score': 1.0, 'Aggregated balanced accuracy score (male)': 0.5, 'Aggregated balanced accuracy score (female)': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best hyperparameter----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['depression']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['depression']\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c92ae3-3e04-4c44-9e31-d877e0fd120d",
   "metadata": {},
   "source": [
    "### Model attempt: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9664eb69-d8e0-476b-8d83-49faf5c32fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for num_trees 5\n",
      "{'Total accuracy': 0.7819449541284403, 'Total Balanced accuracy': 0.7000810674329243, 'Total EO': 0.9385183644605913, 'Aggregated accuracy score': 0.8482758620689654, 'Aggregated balanced accuracy score': 0.7301587301587301, 'Aggregated EO score': 0.8333333333333334, 'Aggregated balanced accuracy score (male)': 0.6916666666666667, 'Aggregated balanced accuracy score (female)': 0.7666666666666666}\n",
      "\n",
      "for num_trees 10\n",
      "{'Total accuracy': 0.8041100917431192, 'Total Balanced accuracy': 0.6930814358470765, 'Total EO': 0.931210586625507, 'Aggregated accuracy score': 0.8160919540229885, 'Aggregated balanced accuracy score': 0.6666666666666667, 'Aggregated EO score': 0.8000000000000002, 'Aggregated balanced accuracy score (male)': 0.625, 'Aggregated balanced accuracy score (female)': 0.7083333333333333}\n",
      "\n",
      "for num_trees 15\n",
      "{'Total accuracy': 0.8192293577981651, 'Total Balanced accuracy': 0.7253014640170138, 'Total EO': 0.938771098013295, 'Aggregated accuracy score': 0.8459770114942529, 'Aggregated balanced accuracy score': 0.7208333333333333, 'Aggregated EO score': 0.8166666666666667, 'Aggregated balanced accuracy score (male)': 0.675, 'Aggregated balanced accuracy score (female)': 0.7666666666666668}\n",
      "\n",
      "for num_trees 20\n",
      "{'Total accuracy': 0.8171009174311926, 'Total Balanced accuracy': 0.7094896113106858, 'Total EO': 0.9386161731528354, 'Aggregated accuracy score': 0.8183908045977011, 'Aggregated balanced accuracy score': 0.6708333333333333, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.65, 'Aggregated balanced accuracy score (female)': 0.6916666666666667}\n",
      "\n",
      "for num_trees 50\n",
      "{'Total accuracy': 0.8317798165137615, 'Total Balanced accuracy': 0.7305060755335421, 'Total EO': 0.9470771641065113, 'Aggregated accuracy score': 0.8390804597701148, 'Aggregated balanced accuracy score': 0.7083333333333334, 'Aggregated EO score': 0.8333333333333333, 'Aggregated balanced accuracy score (male)': 0.6666666666666666, 'Aggregated balanced accuracy score (female)': 0.75}\n",
      "\n",
      "for num_trees 70\n",
      "{'Total accuracy': 0.8339816513761468, 'Total Balanced accuracy': 0.733677170462687, 'Total EO': 0.9468574923444301, 'Aggregated accuracy score': 0.8413793103448276, 'Aggregated balanced accuracy score': 0.7124999999999999, 'Aggregated EO score': 0.8166666666666667, 'Aggregated balanced accuracy score (male)': 0.6666666666666666, 'Aggregated balanced accuracy score (female)': 0.7583333333333334}\n",
      "\n",
      "for num_trees 100\n",
      "{'Total accuracy': 0.8376513761467891, 'Total Balanced accuracy': 0.7381970527480186, 'Total EO': 0.9467769886251922, 'Aggregated accuracy score': 0.8413793103448276, 'Aggregated balanced accuracy score': 0.7125, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.675, 'Aggregated balanced accuracy score (female)': 0.75}\n",
      "\n",
      "for num_trees 500\n",
      "{'Total accuracy': 0.8397798165137615, 'Total Balanced accuracy': 0.7389151741764162, 'Total EO': 0.9413218065839144, 'Aggregated accuracy score': 0.8574712643678162, 'Aggregated balanced accuracy score': 0.7416666666666666, 'Aggregated EO score': 0.7666666666666666, 'Aggregated balanced accuracy score (male)': 0.6833333333333333, 'Aggregated balanced accuracy score (female)': 0.8}\n",
      "\n",
      "for num_trees 1000\n",
      "{'Total accuracy': 0.8405871559633027, 'Total Balanced accuracy': 0.7398452747355242, 'Total EO': 0.9410424937686523, 'Aggregated accuracy score': 0.850574712643678, 'Aggregated balanced accuracy score': 0.7291666666666667, 'Aggregated EO score': 0.7833333333333332, 'Aggregated balanced accuracy score (male)': 0.675, 'Aggregated balanced accuracy score (female)': 0.7833333333333334}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['depression']\n",
    "\n",
    "# Define a list of different numbers of trees to experiment with\n",
    "num_trees_list = [5, 10, 15, 20, 50, 70, 100, 500, 1000]\n",
    "\n",
    "# Initialize list to store results\n",
    "metrics_rf = {}\n",
    "\n",
    "# Iterate over each number of trees\n",
    "for num_trees in num_trees_list:\n",
    "    # Initialize model\n",
    "    model = RandomForestClassifier(n_estimators=num_trees, random_state=42)\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index]))\n",
    "\n",
    "    #find avg metrics for each depth\n",
    "    metrics_rf[num_trees] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    metrics_rf[num_trees] = sums\n",
    "\n",
    "#Print metrics for all the hyperparameters (Depth)\n",
    "for num_trees in metrics_rf:\n",
    "    print(f\"for num_trees {num_trees}\")\n",
    "    print(metrics_rf[num_trees])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00136d70-d85a-4b7a-88e3-27da5684715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.7460365853658537, 'Total Balanced accuracy': 0.4824551819318852, 'Total EO': 0.7718734639421388, 'Aggregated accuracy score': 0.65, 'Aggregated balanced accuracy score': 0.4642857142857143, 'Aggregated EO score': 1.0, 'Aggregated balanced accuracy score (male)': 0.45454545454545453, 'Aggregated balanced accuracy score (female)': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best num_trees----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['depression']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['depression']\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "best_num_trees = 500\n",
    "model = RandomForestClassifier(n_estimators=best_num_trees, random_state=1)\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64668e24-c538-4df4-83c8-89f9676d6510",
   "metadata": {},
   "source": [
    "### Model attempt: AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a31505e-63cd-45b0-b502-0789f5c9b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7305688073394496, 'Total Balanced accuracy': 0.5573661655081127, 'Total EO': 0.9480545632430669, 'Aggregated accuracy score': 0.7471264367816092, 'Aggregated balanced accuracy score': 0.5416666666666666, 'Aggregated EO score': 0.8333333333333334, 'Aggregated balanced accuracy score (male)': 0.5833333333333334, 'Aggregated balanced accuracy score (female)': 0.5}\n",
      "{'n_estimators': 10, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.729467889908257, 'Total Balanced accuracy': 0.5635483158212631, 'Total EO': 0.9452287809099952, 'Aggregated accuracy score': 0.7448275862068966, 'Aggregated balanced accuracy score': 0.5374999999999999, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.5750000000000001, 'Aggregated balanced accuracy score (female)': 0.5}\n",
      "{'n_estimators': 20, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7310825688073395, 'Total Balanced accuracy': 0.5759445365113705, 'Total EO': 0.9480179997505545, 'Aggregated accuracy score': 0.7494252873563219, 'Aggregated balanced accuracy score': 0.5458333333333333, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.5833333333333334, 'Aggregated balanced accuracy score (female)': 0.5083333333333333}\n",
      "{'n_estimators': 50, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7428256880733944, 'Total Balanced accuracy': 0.6031677587186264, 'Total EO': 0.9521265047480032, 'Aggregated accuracy score': 0.7540229885057471, 'Aggregated balanced accuracy score': 0.5567460317460318, 'Aggregated EO score': 0.9, 'Aggregated balanced accuracy score (male)': 0.5833333333333334, 'Aggregated balanced accuracy score (female)': 0.5291666666666666}\n",
      "{'n_estimators': 100, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7516330275229358, 'Total Balanced accuracy': 0.6280219843151257, 'Total EO': 0.9469279309526474, 'Aggregated accuracy score': 0.7816091954022988, 'Aggregated balanced accuracy score': 0.6041666666666666, 'Aggregated EO score': 0.9166666666666666, 'Aggregated balanced accuracy score (male)': 0.5833333333333334, 'Aggregated balanced accuracy score (female)': 0.625}\n",
      "{'n_estimators': 200, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7565504587155963, 'Total Balanced accuracy': 0.6455517472628782, 'Total EO': 0.9544824961095543, 'Aggregated accuracy score': 0.7885057471264367, 'Aggregated balanced accuracy score': 0.6192460317460317, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.5833333333333334, 'Aggregated balanced accuracy score (female)': 0.6541666666666666}\n",
      "{'n_estimators': 500, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7580917431192661, 'Total Balanced accuracy': 0.6596718929335543, 'Total EO': 0.9559109570884085, 'Aggregated accuracy score': 0.8068965517241379, 'Aggregated balanced accuracy score': 0.652579365079365, 'Aggregated EO score': 0.7833333333333332, 'Aggregated balanced accuracy score (male)': 0.6, 'Aggregated balanced accuracy score (female)': 0.7041666666666667}\n",
      "{'n_estimators': 1000, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.7595596330275229, 'Total Balanced accuracy': 0.6663425421186202, 'Total EO': 0.9519511587984868, 'Aggregated accuracy score': 0.8160919540229885, 'Aggregated balanced accuracy score': 0.6692460317460317, 'Aggregated EO score': 0.7166666666666666, 'Aggregated balanced accuracy score (male)': 0.6, 'Aggregated balanced accuracy score (female)': 0.7375}\n",
      "{'n_estimators': 100, 'learning_rate': 0.1}\n",
      "{'Total accuracy': 0.7359266055045872, 'Total Balanced accuracy': 0.5578669750822278, 'Total EO': 0.9573695997340312, 'Aggregated accuracy score': 0.7448275862068966, 'Aggregated balanced accuracy score': 0.5374999999999999, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.5750000000000001, 'Aggregated balanced accuracy score (female)': 0.5}\n",
      "{'n_estimators': 100, 'learning_rate': 0.5}\n",
      "{'Total accuracy': 0.7446605504587156, 'Total Balanced accuracy': 0.5898594035960578, 'Total EO': 0.9499060904586922, 'Aggregated accuracy score': 0.7471264367816092, 'Aggregated balanced accuracy score': 0.5442460317460317, 'Aggregated EO score': 0.85, 'Aggregated balanced accuracy score (male)': 0.5833333333333334, 'Aggregated balanced accuracy score (female)': 0.5041666666666667}\n"
     ]
    }
   ],
   "source": [
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['depression']\n",
    "\n",
    "# Define a list of different hyperparams of trees to experiment with\n",
    "hyperparams = [\n",
    "    {'n_estimators': 5, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 10, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 20, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 50, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 100, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 200, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 500, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 1000, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 100, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 100, 'learning_rate': 0.5},\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate over each number of trees\n",
    "for hyperparam in hyperparams:\n",
    "    print(hyperparam)\n",
    "    # Initialize model\n",
    "    model = AdaBoostClassifier(estimator=None, n_estimators=hyperparam['n_estimators'], learning_rate=hyperparam['learning_rate'], random_state=42)\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index]))\n",
    "\n",
    "    #find avg metrics for each depth\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70336738-14fa-4d06-8e48-c4a5df2ae048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.6344512195121951, 'Total Balanced accuracy': 0.5610532066303426, 'Total EO': 0.7849343444982797, 'Aggregated accuracy score': 0.6, 'Aggregated balanced accuracy score': 0.47619047619047616, 'Aggregated EO score': 0.8, 'Aggregated balanced accuracy score (male)': 0.36363636363636365, 'Aggregated balanced accuracy score (female)': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best hyperparameter----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['depression']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['depression']\n",
    "\n",
    "# Initialize decision tree model\n",
    "model = AdaBoostClassifier(estimator=None, n_estimators=1000, learning_rate=1.0, random_state=42)\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d403e2b-dbce-48a9-b79b-4a2843b43ed7",
   "metadata": {},
   "source": [
    "### Model attempt: Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7d19e5-d7d1-476c-a112-237fda7de4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1'}\n",
      "{'Total accuracy': 0.6464587155963304, 'Total Balanced accuracy': 0.5681661948483416, 'Total EO': 0.9466788052818206, 'Aggregated accuracy score': 0.7149425287356321, 'Aggregated balanced accuracy score': 0.5890873015873016, 'Aggregated EO score': 0.7833333333333333, 'Aggregated balanced accuracy score (male)': 0.5538461538461539, 'Aggregated balanced accuracy score (female)': 0.6333333333333334}\n",
      "{'penalty': 'l2'}\n",
      "{'Total accuracy': 0.6399266055045871, 'Total Balanced accuracy': 0.5727839452622211, 'Total EO': 0.9527539484807953, 'Aggregated accuracy score': 0.7057471264367816, 'Aggregated balanced accuracy score': 0.577579365079365, 'Aggregated EO score': 0.6166666666666667, 'Aggregated balanced accuracy score (male)': 0.5326923076923077, 'Aggregated balanced accuracy score (female)': 0.5958333333333333}\n",
      "{'penalty': None}\n",
      "{'Total accuracy': 0.6422752293577981, 'Total Balanced accuracy': 0.5640207194817426, 'Total EO': 0.9474830249543057, 'Aggregated accuracy score': 0.7126436781609196, 'Aggregated balanced accuracy score': 0.5849206349206348, 'Aggregated EO score': 0.6333333333333333, 'Aggregated balanced accuracy score (male)': 0.5378205128205129, 'Aggregated balanced accuracy score (female)': 0.625}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['depression']\n",
    "\n",
    "hyperparams = [\n",
    "    {'penalty': 'l1'},\n",
    "    {'penalty': 'l2'},\n",
    "    {'penalty': None}\n",
    "]\n",
    "\n",
    "for hyperparam in hyperparams:\n",
    "    print(hyperparam)\n",
    "    # Initialize Logistic regression model\n",
    "    model = Perceptron(penalty=hyperparam['penalty'])\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index]))\n",
    "    \n",
    "    #find avg metrics for each depth\n",
    "    # metrics[depth] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f9d528-799d-4f6c-9366-4112d74e065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.49817073170731707, 'Total Balanced accuracy': 0.44699032476027545, 'Total EO': 0.8446738290850362, 'Aggregated accuracy score': 0.4, 'Aggregated balanced accuracy score': 0.38095238095238093, 'Aggregated EO score': 0.19999999999999996, 'Aggregated balanced accuracy score (male)': 0.6818181818181819, 'Aggregated balanced accuracy score (female)': 0.43333333333333335}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best hyperparameter----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['depression']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['depression']\n",
    "\n",
    "model = Perceptron(penalty='l1')\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92db6b28-59d3-4cf1-8f0d-bc2bad32ec8c",
   "metadata": {},
   "source": [
    "## Gender Classification\n",
    "\n",
    "### Model attempt: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b20b755e-79fe-4ae6-8248-c1e4979b47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth 3\n",
      "{'Total accuracy': 0.9236697247706422, 'Total Balanced accuracy': 0.9192004514666632, 'Aggregated accuracy score': 0.9862068965517242, 'Aggregated balanced accuracy score': 0.9841503267973856}\n",
      "\n",
      "for depth 5\n",
      "{'Total accuracy': 0.9288073394495413, 'Total Balanced accuracy': 0.9226857638489625, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for depth 7\n",
      "{'Total accuracy': 0.9288073394495413, 'Total Balanced accuracy': 0.9257402712308427, 'Aggregated accuracy score': 0.9954022988505746, 'Aggregated balanced accuracy score': 0.9944444444444445}\n",
      "\n",
      "for depth 9\n",
      "{'Total accuracy': 0.927045871559633, 'Total Balanced accuracy': 0.9238335826876496, 'Aggregated accuracy score': 0.9954022988505746, 'Aggregated balanced accuracy score': 0.9944444444444445}\n",
      "\n",
      "for depth 15\n",
      "{'Total accuracy': 0.924697247706422, 'Total Balanced accuracy': 0.9218074709566804, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for depth 30\n",
      "{'Total accuracy': 0.9216146788990827, 'Total Balanced accuracy': 0.9188744905237696, 'Aggregated accuracy score': 0.9908045977011494, 'Aggregated balanced accuracy score': 0.9888888888888889}\n",
      "\n",
      "for depth 50\n",
      "{'Total accuracy': 0.9233027522935778, 'Total Balanced accuracy': 0.9204073969555904, 'Aggregated accuracy score': 0.9908045977011494, 'Aggregated balanced accuracy score': 0.9888888888888889}\n",
      "\n",
      "for depth 70\n",
      "{'Total accuracy': 0.9244036697247706, 'Total Balanced accuracy': 0.9216677643184379, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for depth 90\n",
      "{'Total accuracy': 0.9216146788990827, 'Total Balanced accuracy': 0.9185705978568199, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------Tuning for different depths-------------------------------------------------------\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['gender']\n",
    "\n",
    "# Define the depths to experiment with\n",
    "depths = [3, 5, 7, 9, 15, 30, 50, 70, 90]\n",
    "# Initialize metrics\n",
    "metrics = {}\n",
    "\n",
    "# Perform cross-validation for each tree depth\n",
    "for depth in depths:\n",
    "    # Initialize decision tree model\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, criterion='entropy')\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        #Fit the training set\n",
    "        tree.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = tree.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index], False))\n",
    "\n",
    "    #find avg metrics for each depth\n",
    "    metrics[depth] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    metrics[depth] = sums\n",
    "\n",
    "#Print metrics for all the hyperparameters (Depth)\n",
    "for depth in metrics:\n",
    "    print(f\"for depth {depth}\")\n",
    "    print(metrics[depth])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35cad93c-f60c-47b3-b719-6c5da14f245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.8634146341463415, 'Total Balanced accuracy': 0.8574221257082024, 'Aggregated accuracy score': 0.95, 'Aggregated balanced accuracy score': 0.9375}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best depth----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['gender']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['gender']\n",
    "\n",
    "best_depth = 70\n",
    "# Initialize decision tree model\n",
    "tree = DecisionTreeClassifier(max_depth=best_depth, criterion='entropy')\n",
    "#Fit the training set\n",
    "tree.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = tree.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data, False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00895fa1-0a47-4349-8e1c-42c12c44f742",
   "metadata": {},
   "source": [
    "### Model attempt: Logistic regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47738aac-2bf7-45d7-b188-84b7c019e26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'C': 1.0, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.9479633027522937, 'Total Balanced accuracy': 0.9445513343092851, 'Aggregated accuracy score': 1.0, 'Aggregated balanced accuracy score': 1.0}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.9472293577981651, 'Total Balanced accuracy': 0.9434794099222874, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 0.99, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.9472293577981651, 'Total Balanced accuracy': 0.9434794099222874, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 0.95, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.9471559633027521, 'Total Balanced accuracy': 0.9434183225673698, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 0.9, 'solver': 'liblinear'}\n",
      "{'Total accuracy': 0.9471559633027521, 'Total Balanced accuracy': 0.9434183225673698, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'lbfgs'}\n",
      "{'Total accuracy': 0.9472293577981652, 'Total Balanced accuracy': 0.9434210488824508, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'sag'}\n",
      "{'Total accuracy': 0.9410642201834862, 'Total Balanced accuracy': 0.9366312534411829, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'saga'}\n",
      "{'Total accuracy': 0.9399633027522935, 'Total Balanced accuracy': 0.935587959142639, 'Aggregated accuracy score': 0.9954022988505746, 'Aggregated balanced accuracy score': 0.9944444444444445}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cg'}\n",
      "{'Total accuracy': 0.9472293577981651, 'Total Balanced accuracy': 0.9434794099222874, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cholesky'}\n",
      "{'Total accuracy': 0.9472293577981651, 'Total Balanced accuracy': 0.9434794099222874, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['gender']\n",
    "\n",
    "hyperparams = [\n",
    "    {'penalty': 'l1', 'C': 1.0, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 0.99, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 0.95, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 0.9, 'solver': 'liblinear'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'lbfgs'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'sag'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'saga'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cg'},\n",
    "    {'penalty': 'l2', 'C': 1.0, 'solver': 'newton-cholesky'},\n",
    "]\n",
    "\n",
    "for hyperparam in hyperparams:\n",
    "    print(hyperparam)\n",
    "    # Initialize Logistic regression model\n",
    "    model = LogisticRegression(solver=hyperparam['solver'], C=hyperparam['C'], penalty=hyperparam['penalty'])\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index], False))\n",
    "    \n",
    "    #find avg metrics for each depth\n",
    "    # metrics[depth] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51b39ecb-6bfe-484c-9a3c-79f9769d038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.8759146341463414, 'Total Balanced accuracy': 0.8733573414574689, 'Aggregated accuracy score': 0.9, 'Aggregated balanced accuracy score': 0.8958333333333333}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best hyperparameter----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['gender']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['gender']\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=1.0, solver='liblinear')\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data, False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4fbc5-00cc-4f9c-bb04-c7c426054925",
   "metadata": {},
   "source": [
    "### Model attempt: Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34039e6e-eb5b-4c2f-8121-8e78646caa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for num_trees 5\n",
      "{'Total accuracy': 0.9354128440366974, 'Total Balanced accuracy': 0.932551379725797, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for num_trees 10\n",
      "{'Total accuracy': 0.9395229357798165, 'Total Balanced accuracy': 0.9390879733703412, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for num_trees 15\n",
      "{'Total accuracy': 0.9431192660550458, 'Total Balanced accuracy': 0.9402023270255062, 'Aggregated accuracy score': 0.9908045977011494, 'Aggregated balanced accuracy score': 0.9888888888888889}\n",
      "\n",
      "for num_trees 20\n",
      "{'Total accuracy': 0.944, 'Total Balanced accuracy': 0.9423465197030889, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for num_trees 50\n",
      "{'Total accuracy': 0.9478899082568807, 'Total Balanced accuracy': 0.9463822431074927, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for num_trees 70\n",
      "{'Total accuracy': 0.9485504587155964, 'Total Balanced accuracy': 0.9466558697657673, 'Aggregated accuracy score': 0.9908045977011494, 'Aggregated balanced accuracy score': 0.9888888888888889}\n",
      "\n",
      "for num_trees 100\n",
      "{'Total accuracy': 0.9487706422018348, 'Total Balanced accuracy': 0.9468055003050789, 'Aggregated accuracy score': 0.9908045977011494, 'Aggregated balanced accuracy score': 0.9888888888888889}\n",
      "\n",
      "for num_trees 500\n",
      "{'Total accuracy': 0.9487706422018348, 'Total Balanced accuracy': 0.9464668610260943, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "\n",
      "for num_trees 1000\n",
      "{'Total accuracy': 0.9489908256880734, 'Total Balanced accuracy': 0.9467085096834555, 'Aggregated accuracy score': 0.9908045977011494, 'Aggregated balanced accuracy score': 0.9888888888888889}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['gender']\n",
    "\n",
    "# Define a list of different numbers of trees to experiment with\n",
    "num_trees_list = [5, 10, 15, 20, 50, 70, 100, 500, 1000]\n",
    "\n",
    "# Initialize list to store results\n",
    "metrics_rf = {}\n",
    "\n",
    "# Iterate over each number of trees\n",
    "for num_trees in num_trees_list:\n",
    "    # Initialize model\n",
    "    model = RandomForestClassifier(n_estimators=num_trees, random_state=42)\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index], False))\n",
    "\n",
    "    #find avg metrics for each depth\n",
    "    metrics_rf[num_trees] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    metrics_rf[num_trees] = sums\n",
    "\n",
    "#Print metrics for all the hyperparameters (Depth)\n",
    "for num_trees in metrics_rf:\n",
    "    print(f\"for num_trees {num_trees}\")\n",
    "    print(metrics_rf[num_trees])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9355b354-6de1-4e50-8cf0-e27e23a34a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.8975609756097561, 'Total Balanced accuracy': 0.8925856270787773, 'Aggregated accuracy score': 0.95, 'Aggregated balanced accuracy score': 0.9375}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best num_trees----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['gender']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['gender']\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "best_num_trees = 500\n",
    "# Initialize decision tree model\n",
    "model = RandomForestClassifier(n_estimators=best_num_trees, random_state=42)\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data, False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491224b-766d-4b21-b98d-1fdf882044aa",
   "metadata": {},
   "source": [
    "### Model attempt: Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4255b642-405d-4b9a-9ff1-d8fe6645dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 5, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.9187522935779817, 'Total Balanced accuracy': 0.9132265743408574, 'Aggregated accuracy score': 0.9793103448275863, 'Aggregated balanced accuracy score': 0.975}\n",
      "{'n_estimators': 10, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.9202935779816513, 'Total Balanced accuracy': 0.9134970912682283, 'Aggregated accuracy score': 0.9770114942528736, 'Aggregated balanced accuracy score': 0.9722222222222221}\n",
      "{'n_estimators': 20, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.9342385321100919, 'Total Balanced accuracy': 0.9289966349024745, 'Aggregated accuracy score': 0.993103448275862, 'Aggregated balanced accuracy score': 0.9916666666666668}\n",
      "{'n_estimators': 50, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.943045871559633, 'Total Balanced accuracy': 0.9387751418931648, 'Aggregated accuracy score': 0.9954022988505746, 'Aggregated balanced accuracy score': 0.9944444444444445}\n",
      "{'n_estimators': 100, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.9460550458715596, 'Total Balanced accuracy': 0.9426461731908728, 'Aggregated accuracy score': 0.9954022988505746, 'Aggregated balanced accuracy score': 0.9944444444444445}\n",
      "{'n_estimators': 200, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.9502385321100919, 'Total Balanced accuracy': 0.9472065294427043, 'Aggregated accuracy score': 1.0, 'Aggregated balanced accuracy score': 1.0}\n",
      "{'n_estimators': 500, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.9517798165137614, 'Total Balanced accuracy': 0.9491038712245828, 'Aggregated accuracy score': 1.0, 'Aggregated balanced accuracy score': 1.0}\n",
      "{'n_estimators': 1000, 'learning_rate': 1.0}\n",
      "{'Total accuracy': 0.951559633027523, 'Total Balanced accuracy': 0.9484832512456508, 'Aggregated accuracy score': 0.9977011494252874, 'Aggregated balanced accuracy score': 0.9972222222222221}\n",
      "{'n_estimators': 100, 'learning_rate': 0.1}\n",
      "{'Total accuracy': 0.9323302752293579, 'Total Balanced accuracy': 0.9261950411049957, 'Aggregated accuracy score': 0.9816091954022989, 'Aggregated balanced accuracy score': 0.9777777777777779}\n",
      "{'n_estimators': 100, 'learning_rate': 0.5}\n",
      "{'Total accuracy': 0.946348623853211, 'Total Balanced accuracy': 0.9421338982215716, 'Aggregated accuracy score': 0.9954022988505746, 'Aggregated balanced accuracy score': 0.9944444444444445}\n"
     ]
    }
   ],
   "source": [
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['gender']\n",
    "\n",
    "# Define a list of different hyperparams of trees to experiment with\n",
    "hyperparams = [\n",
    "    {'n_estimators': 5, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 10, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 20, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 50, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 100, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 200, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 500, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 1000, 'learning_rate': 1.0},\n",
    "    {'n_estimators': 100, 'learning_rate': 0.1},\n",
    "    {'n_estimators': 100, 'learning_rate': 0.5},\n",
    "]\n",
    "\n",
    "\n",
    "# Iterate over each number of trees\n",
    "for hyperparam in hyperparams:\n",
    "    print(hyperparam)\n",
    "    # Initialize model\n",
    "    model = AdaBoostClassifier(estimator=None, n_estimators=hyperparam['n_estimators'], learning_rate=hyperparam['learning_rate'], random_state=42)\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "\n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index], False))\n",
    "\n",
    "    #find avg metrics for each depth\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17aed4ee-caa1-4c30-bc6b-0a9384af9029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.8829268292682927, 'Total Balanced accuracy': 0.881426716928279, 'Aggregated accuracy score': 0.9, 'Aggregated balanced accuracy score': 0.8958333333333333}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best hyperparameter----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['gender']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['gender']\n",
    "\n",
    "# Initialize decision tree model\n",
    "model = AdaBoostClassifier(estimator=None, n_estimators=500, learning_rate=1.0, random_state=42)\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data, False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e89d6-37ba-4d38-afaf-3735bbdfc7ae",
   "metadata": {},
   "source": [
    "### Model attempt: Linear Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38bce20b-bccb-4d76-b9f0-80d315eb9f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1'}\n",
      "{'Total accuracy': 0.9233027522935779, 'Total Balanced accuracy': 0.920602012965162, 'Aggregated accuracy score': 0.9816091954022989, 'Aggregated balanced accuracy score': 0.981045751633987}\n",
      "{'penalty': 'l2'}\n",
      "{'Total accuracy': 0.9127339449541283, 'Total Balanced accuracy': 0.9096748165836269, 'Aggregated accuracy score': 0.9816091954022989, 'Aggregated balanced accuracy score': 0.9794117647058822}\n",
      "{'penalty': None}\n",
      "{'Total accuracy': 0.9219816513761467, 'Total Balanced accuracy': 0.9184822491797735, 'Aggregated accuracy score': 0.9908045977011495, 'Aggregated balanced accuracy score': 0.9905228758169935}\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "training_data = preprocess_data(training_df)\n",
    "X = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y = training_data['gender']\n",
    "\n",
    "hyperparams = [\n",
    "    {'penalty': 'l1'},\n",
    "    {'penalty': 'l2'},\n",
    "    {'penalty': None}\n",
    "]\n",
    "\n",
    "for hyperparam in hyperparams:\n",
    "    print(hyperparam)\n",
    "    # Initialize Logistic regression model\n",
    "    model = Perceptron(penalty=hyperparam['penalty'])\n",
    "    # Cross validation k fold, 4:1::training:validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    #list to store metrics for each cross validation split\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Perform cross-validation and collect metrics\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "        #Fit the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        #Predict validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "        #calculate metrics\n",
    "        fold_metrics.append(calculate_metrics(y_val, y_pred, training_data.iloc[val_index], False))\n",
    "    \n",
    "    #find avg metrics for each depth\n",
    "    # metrics[depth] = {}\n",
    "    sums = {}\n",
    "    for metric in fold_metrics:\n",
    "        for key, value in metric.items():\n",
    "            sums[key] = sums.get(key, 0) + value\n",
    "    for key in sums:\n",
    "        sums[key]/=len(fold_metrics)\n",
    "    print(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0acc7c02-e76a-43b1-851f-3681bf256ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total accuracy': 0.8774390243902439, 'Total Balanced accuracy': 0.8808123821625446, 'Aggregated accuracy score': 1.0, 'Aggregated balanced accuracy score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------Testing for best hyperparameter----------------------------------------------------------------\n",
    "test_data = preprocess_data(test_df)\n",
    "training_data = preprocess_data(training_df)\n",
    "X_train = training_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_train = training_data['gender']\n",
    "X_test = test_data.drop(columns = ['participant', 'gender', 'depression'], axis=1)\n",
    "y_test = test_data['gender']\n",
    "\n",
    "# Initialize decision tree model\n",
    "model = Perceptron(penalty=None)\n",
    "#Fit the training set\n",
    "model.fit(X_train, y_train)\n",
    "#Predict for test set\n",
    "y_pred = model.predict(X_test)\n",
    "#get metrics\n",
    "metrics = calculate_metrics(y_test, y_pred, test_data, False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3606e-b51d-4e5e-ad9b-dcb9ca3572cc",
   "metadata": {},
   "source": [
    "## Current model performance\n",
    "### Depression classification\n",
    "- Linear Perceptron (Penalty: l1)\n",
    "  {'Total accuracy': 0.49817073170731707, 'Total Balanced accuracy': 0.44699032476027545, 'Total EO': 0.8446738290850362, 'Aggregated accuracy score': 0.4, 'Aggregated balanced accuracy score': 0.38095238095238093, 'Aggregated EO score': 0.19999999999999996, 'Aggregated balanced accuracy score (male)': 0.6818181818181819, 'Aggregated balanced accuracy score (female)': 0.43333333333333335}\n",
    "- Logistic Regression (Penalty: l1, C:1.0, solver: liblinear)\n",
    "  {'Total accuracy': 0.761890243902439, 'Total Balanced accuracy': 0.5125821245273796, 'Total EO': 0.9488448844884488, 'Aggregated accuracy score': 0.7, 'Aggregated balanced accuracy score': 0.5, 'Aggregated EO score': 1.0, 'Aggregated balanced accuracy score (male)': 0.5, 'Aggregated balanced accuracy score (female)': 0.5}\n",
    "- Decision Tree Classifier (Depth:70)\n",
    "  **{'Total accuracy': 0.688109756097561, 'Total Balanced accuracy': 0.5868557627337944, 'Total EO': 0.7612878309107507, 'Aggregated accuracy score': 0.7, 'Aggregated balanced accuracy score': 0.5476190476190477, 'Aggregated EO score': 0.8, 'Aggregated balanced accuracy score (male)': 0.45454545454545453, 'Aggregated balanced accuracy score (female)': 0.6}**\n",
    "- Random forest classifier (num trees: 500)\n",
    "  {'Total accuracy': 0.7460365853658537, 'Total Balanced accuracy': 0.4824551819318852, 'Total EO': 0.7718734639421388, 'Aggregated accuracy score': 0.65, 'Aggregated balanced accuracy score': 0.4642857142857143, 'Aggregated EO score': 1.0, 'Aggregated balanced accuracy score (male)': 0.45454545454545453, 'Aggregated balanced accuracy score (female)': 0.5}\n",
    "- Adaboost classifier (estimators: 1000, learning rate: 1.0)\n",
    "{'Total accuracy': 0.6344512195121951, 'Total Balanced accuracy': 0.5610532066303426, 'Total EO': 0.7849343444982797, 'Aggregated accuracy score': 0.6, 'Aggregated balanced accuracy score': 0.47619047619047616, 'Aggregated EO score': 0.8, 'Aggregated balanced accuracy score (male)': 0.36363636363636365, 'Aggregated balanced accuracy score (female)': 0.6}\n",
    "\n",
    "\n",
    "### Gender classification\n",
    "- Linear Perceptron (Penalty: None)\n",
    "  **{'Total accuracy': 0.8774390243902439, 'Total Balanced accuracy': 0.8808123821625446, 'Aggregated accuracy score': 1.0, 'Aggregated balanced accuracy score': 1.0}**\n",
    "- Logistic Regression (Penalty: l1, C:1.0, solver: liblinear)\n",
    "  {'Total accuracy': 0.876219512195122, 'Total Balanced accuracy': 0.8736052343677317, 'Aggregated accuracy score': 0.9, 'Aggregated balanced accuracy score': 0.8958333333333333}\n",
    "- Decision Tree Classifier (Depth:70)\n",
    "  {'Total accuracy': 0.864329268292683, 'Total Balanced accuracy': 0.856241935629493, 'Aggregated accuracy score': 0.95, 'Aggregated balanced accuracy score': 0.9375}\n",
    "- Random forest classifier (num trees: 500)\n",
    "  {'Total accuracy': 0.8975609756097561, 'Total Balanced accuracy': 0.8925856270787773, 'Aggregated accuracy score': 0.95, 'Aggregated balanced accuracy score': 0.9375}\n",
    "- Adaboost Classifier (estimators: 500, learning rate: 1.0)\n",
    "{'Total accuracy': 0.8829268292682927, 'Total Balanced accuracy': 0.881426716928279, 'Aggregated accuracy score': 0.9, 'Aggregated balanced accuracy score': 0.8958333333333333}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee45ad-fa53-47a1-96d6-f22aa2833acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
